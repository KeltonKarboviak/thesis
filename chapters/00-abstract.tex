%\begin{abstract}
This paper examines the used of feature detection, machine learning, and background subtraction algorithms to classify and detect events of interest withing uncontrolled outdoor avian nesting video from the Wildlife@Home project. We tested feature detection and machine learning using Speeded Up Robust Features (SURF) and a Support Vector Machine (SVM) along with three background subtraction algorithms --- Mixture of Gaussans (MOG), ViBe, and Pixel-Based Adaptive Segmentation (PBAS) --- as methods to automatically detect and classify events from surveillance cameras. Modifications to ViBe and PBAS are shown to provide robust results and compensate for issues caused by cryptic coloration of the monitored species. Both methods utilize the Berkeley Open Infrastructure for Network Computing (BOINC) in order to more quickly analyze the 85,000+ hours of video in the Wildlife@Home project. The feature detection and machine learning technique failed to handle the many variables of the low quality uncontrolled outdoor video and was succeeded by the background subtraction work where the modified version of PBAS is shown to provide accurate detection of events.
%\end{abstract}

